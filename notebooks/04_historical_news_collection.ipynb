{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Phase 1E: Historical News Collection & Decoupled Architecture\n",
    "## Building Real Historical News Pipeline for Strategy Validation\n",
    "\n",
    "**Mission**: Collect real historical financial news for Intel (INTC), AMD, and NVIDIA to enable proper backtesting of our sentiment-based trading strategy.\n",
    "\n",
    "**Key Improvements**:\n",
    "- ‚úÖ **Real Historical Data**: GDELT Project (free) + Polygon.io (paid option)\n",
    "- ‚úÖ **Decoupled Architecture**: Separate news collection from sentiment analysis\n",
    "- ‚úÖ **Aggressive OpenAI Usage**: 10-20 second intervals, batch processing\n",
    "- ‚úÖ **Cost Optimization**: Reprocess sentiment without re-fetching news\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Setup and Database Schema Updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Phase 1E: Historical News Collection - Ready!\n",
      "üìä Mission: Build real historical news pipeline for strategy validation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "# Essential imports\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from datetime import datetime, date, timedelta\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local imports\n",
    "from src.database import get_database_connection, get_api_key\n",
    "\n",
    "print(\"üöÄ Phase 1E: Historical News Collection - Ready!\")\n",
    "print(\"üìä Mission: Build real historical news pipeline for strategy validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Decoupled database schema created successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create decoupled database schema\n",
    "def create_decoupled_schema():\n",
    "    \"\"\"Create new tables for decoupled news collection and sentiment analysis\"\"\"\n",
    "    \n",
    "    schema_sql = \"\"\"\n",
    "    -- Raw news articles storage\n",
    "    CREATE TABLE IF NOT EXISTS raw_news_articles (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        symbol_id INTEGER REFERENCES symbols(id),\n",
    "        article_date DATE NOT NULL,\n",
    "        title TEXT NOT NULL,\n",
    "        content TEXT,\n",
    "        summary TEXT,\n",
    "        source VARCHAR(100),\n",
    "        url TEXT,\n",
    "        published_at TIMESTAMP,\n",
    "        relevance_score DECIMAL(3,2),\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        UNIQUE(url, symbol_id)\n",
    "    );\n",
    "    \n",
    "    -- Processed sentiment results\n",
    "    CREATE TABLE IF NOT EXISTS processed_sentiment (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        symbol_id INTEGER REFERENCES symbols(id),\n",
    "        analysis_date DATE NOT NULL,\n",
    "        smo_score DECIMAL(3,2),\n",
    "        smd_score DECIMAL(3,2),\n",
    "        smc_score DECIMAL(3,2),\n",
    "        sms_score DECIMAL(3,2),\n",
    "        sdc_score DECIMAL(3,2),\n",
    "        articles_analyzed INTEGER,\n",
    "        confidence_score DECIMAL(3,2),\n",
    "        analysis_summary TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        UNIQUE(symbol_id, analysis_date)\n",
    "    );\n",
    "    \n",
    "    -- Create indexes\n",
    "    CREATE INDEX IF NOT EXISTS idx_raw_news_symbol_date ON raw_news_articles(symbol_id, article_date);\n",
    "    CREATE INDEX IF NOT EXISTS idx_processed_sentiment_date ON processed_sentiment(symbol_id, analysis_date);\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        engine = get_database_connection()\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(sqlalchemy.text(schema_sql))\n",
    "            conn.commit()\n",
    "        \n",
    "        print(\"‚úÖ Decoupled database schema created successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating schema: {e}\")\n",
    "        return False\n",
    "\n",
    "# Create the new schema\n",
    "create_decoupled_schema()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. EOD Historical Data News Collector (Reliable Alternative)\n",
    "\n",
    "**üîÑ PIVOT DECISION**: GDELT timeouts proved unreliable for production use.  \n",
    "**‚úÖ SWITCHING TO**: EOD Historical Data - proven infrastructure with pre-computed sentiment!\n",
    "\n",
    "**Benefits of EOD approach:**\n",
    "- ‚úÖ **Built-in sentiment analysis** (no OpenAI costs needed!)\n",
    "- ‚úÖ **Reliable infrastructure** (institutional grade)  \n",
    "- ‚úÖ **6+ years historical data** (back to 2019)\n",
    "- ‚úÖ **$19.99/month** vs potential GDELT frustrations\n",
    "- ‚úÖ **Same decoupled architecture** - just swap the data source!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EOD Historical Data News Collector initialized!\n",
      "üèõÔ∏è  Using institutional-grade infrastructure\n",
      "üß† Built-in sentiment analysis (no OpenAI costs!)\n",
      "üìä Ready for reliable historical news + sentiment collection\n"
     ]
    }
   ],
   "source": [
    "class EODHistoricalNewsCollector:\n",
    "    \"\"\"Reliable EOD Historical Data collector with built-in sentiment\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.base_url_news = \"https://eodhd.com/api/news\"\n",
    "        self.base_url_sentiment = \"https://eodhd.com/api/sentiments\"\n",
    "        self.symbols = ['INTC', 'AMD', 'NVDA']\n",
    "        \n",
    "        # Get API key\n",
    "        self.api_key = get_api_key('eod_historical')\n",
    "        if not self.api_key:\n",
    "            print(\"‚ö†Ô∏è  EOD API key not found. Get one at: https://eodhd.com/\")\n",
    "            print(\"üí° Add it to your .env file as: EOD_HISTORICAL_API_KEY=your_key_here\")\n",
    "        \n",
    "        # Symbol mappings for EOD format\n",
    "        self.eod_symbols = {\n",
    "            'INTC': 'INTC.US',\n",
    "            'AMD': 'AMD.US', \n",
    "            'NVDA': 'NVDA.US'\n",
    "        }\n",
    "        \n",
    "    def fetch_historical_news_and_sentiment(self, symbol, start_date, end_date, max_records=50):\n",
    "        \"\"\"Fetch both news and pre-computed sentiment from EOD\"\"\"\n",
    "        \n",
    "        if not self.api_key:\n",
    "            print(\"‚ùå Cannot proceed without EOD API key\")\n",
    "            return []\n",
    "            \n",
    "        eod_symbol = self.eod_symbols.get(symbol, f\"{symbol}.US\")\n",
    "        \n",
    "        print(f\"üîç Collecting news + sentiment for {symbol} ({eod_symbol})\")\n",
    "        print(f\"üìÖ Date range: {start_date.date()} to {end_date.date()}\")\n",
    "        \n",
    "        # Fetch news articles\n",
    "        news_articles = self._fetch_news(eod_symbol, start_date, end_date, max_records)\n",
    "        \n",
    "        # Fetch sentiment data\n",
    "        sentiment_data = self._fetch_sentiment(eod_symbol, start_date, end_date)\n",
    "        \n",
    "        # Combine news with sentiment\n",
    "        enriched_articles = self._enrich_with_sentiment(news_articles, sentiment_data, symbol)\n",
    "        \n",
    "        print(f\"‚úÖ Collected {len(enriched_articles)} articles with sentiment for {symbol}\")\n",
    "        return enriched_articles\n",
    "    \n",
    "    def _fetch_news(self, eod_symbol, start_date, end_date, max_records):\n",
    "        \"\"\"Fetch news articles from EOD\"\"\"\n",
    "        \n",
    "        params = {\n",
    "            's': eod_symbol,\n",
    "            'from': start_date.strftime('%Y-%m-%d'),\n",
    "            'to': end_date.strftime('%Y-%m-%d'),\n",
    "            'limit': max_records,\n",
    "            'api_token': self.api_key,\n",
    "            'fmt': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"üì° Fetching news from EOD API...\")\n",
    "            response = requests.get(self.base_url_news, params=params, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                articles = response.json()\n",
    "                print(f\"üì∞ EOD returned {len(articles)} news articles\")\n",
    "                return articles\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  EOD News API error: {response.status_code}\")\n",
    "                return []\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching news: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _fetch_sentiment(self, eod_symbol, start_date, end_date):\n",
    "        \"\"\"Fetch pre-computed sentiment scores from EOD\"\"\"\n",
    "        \n",
    "        params = {\n",
    "            's': eod_symbol,\n",
    "            'from': start_date.strftime('%Y-%m-%d'),\n",
    "            'to': end_date.strftime('%Y-%m-%d'),\n",
    "            'api_token': self.api_key\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"üß† Fetching sentiment scores from EOD API...\")\n",
    "            response = requests.get(self.base_url_sentiment, params=params, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                sentiment_data = response.json()\n",
    "                \n",
    "                # Extract sentiment by symbol and date\n",
    "                sentiment_by_date = {}\n",
    "                for symbol_data in sentiment_data.values():\n",
    "                    if isinstance(symbol_data, list):\n",
    "                        for entry in symbol_data:\n",
    "                            date_key = entry.get('date')\n",
    "                            if date_key:\n",
    "                                sentiment_by_date[date_key] = {\n",
    "                                    'normalized': entry.get('normalized', 0.0),\n",
    "                                    'count': entry.get('count', 0)\n",
    "                                }\n",
    "                \n",
    "                print(f\"üìä EOD returned sentiment for {len(sentiment_by_date)} dates\")\n",
    "                return sentiment_by_date\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  EOD Sentiment API error: {response.status_code}\")\n",
    "                return {}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error fetching sentiment: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def _enrich_with_sentiment(self, news_articles, sentiment_data, symbol):\n",
    "        \"\"\"Combine news articles with sentiment scores\"\"\"\n",
    "        \n",
    "        enriched = []\n",
    "        \n",
    "        for article in news_articles:\n",
    "            try:\n",
    "                # Parse article date\n",
    "                article_date = datetime.fromisoformat(article.get('date', '').replace('Z', '+00:00'))\n",
    "                date_key = article_date.strftime('%Y-%m-%d')\n",
    "                \n",
    "                # Get sentiment for this date\n",
    "                day_sentiment = sentiment_data.get(date_key, {'normalized': 0.0, 'count': 0})\n",
    "                \n",
    "                enriched_article = {\n",
    "                    'symbol': symbol,\n",
    "                    'title': article.get('title', ''),\n",
    "                    'content': article.get('content', ''),\n",
    "                    'url': article.get('link', ''),\n",
    "                    'published_at': article_date,\n",
    "                    'source': self._extract_source(article.get('link', '')),\n",
    "                    'relevance_score': self._calculate_relevance(article.get('title', ''), symbol),\n",
    "                    \n",
    "                    # Built-in sentiment from EOD (no OpenAI needed!)\n",
    "                    'eod_sentiment_score': day_sentiment['normalized'],\n",
    "                    'eod_sentiment_count': day_sentiment['count']\n",
    "                }\n",
    "                \n",
    "                enriched.append(enriched_article)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Skipping malformed article: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return enriched\n",
    "    \n",
    "    def _extract_source(self, url):\n",
    "        \"\"\"Extract source domain from URL\"\"\"\n",
    "        try:\n",
    "            from urllib.parse import urlparse\n",
    "            parsed = urlparse(url)\n",
    "            return parsed.netloc.replace('www.', '')\n",
    "        except:\n",
    "            return 'unknown'\n",
    "    \n",
    "    def _calculate_relevance(self, title, symbol):\n",
    "        \"\"\"Calculate relevance score for an article\"\"\"\n",
    "        title_lower = title.lower()\n",
    "        score = 0.5  # Base score\n",
    "        \n",
    "        # Boost for direct mentions\n",
    "        if symbol.lower() in title_lower:\n",
    "            score += 0.3\n",
    "        if 'semiconductor' in title_lower or 'chip' in title_lower:\n",
    "            score += 0.2\n",
    "        if 'earnings' in title_lower or 'revenue' in title_lower:\n",
    "            score += 0.3\n",
    "            \n",
    "        return min(1.0, score)\n",
    "\n",
    "# Initialize EOD collector\n",
    "news_collector = EODHistoricalNewsCollector()\n",
    "print(\"‚úÖ EOD Historical Data News Collector initialized!\")\n",
    "print(\"üèõÔ∏è  Using institutional-grade infrastructure\")\n",
    "print(\"üß† Built-in sentiment analysis (no OpenAI costs!)\")\n",
    "print(\"üìä Ready for reliable historical news + sentiment collection\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. News Collection and Storage Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ News collection and storage functions ready!\n"
     ]
    }
   ],
   "source": [
    "def store_eod_news_with_sentiment(articles):\n",
    "    \"\"\"Store EOD news articles with built-in sentiment in database\"\"\"\n",
    "    if not articles:\n",
    "        return 0, 0\n",
    "    \n",
    "    try:\n",
    "        engine = get_database_connection()\n",
    "        stored_articles = 0\n",
    "        stored_sentiment = 0\n",
    "        \n",
    "        with engine.connect() as conn:\n",
    "            for article in articles:\n",
    "                # Get symbol_id\n",
    "                symbol_query = \"SELECT id FROM symbols WHERE symbol = :symbol\"\n",
    "                symbol_result = conn.execute(sqlalchemy.text(symbol_query), {'symbol': article['symbol']})\n",
    "                symbol_row = symbol_result.fetchone()\n",
    "                \n",
    "                if not symbol_row:\n",
    "                    continue\n",
    "                    \n",
    "                symbol_id = symbol_row[0]\n",
    "                \n",
    "                # Store raw news article\n",
    "                article_query = \"\"\"\n",
    "                INSERT INTO raw_news_articles \n",
    "                (symbol_id, article_date, title, content, url, published_at, source, relevance_score)\n",
    "                VALUES (:symbol_id, :article_date, :title, :content, :url, :published_at, :source, :relevance_score)\n",
    "                ON CONFLICT (url, symbol_id) DO NOTHING\n",
    "                \"\"\"\n",
    "                \n",
    "                result = conn.execute(sqlalchemy.text(article_query), {\n",
    "                    'symbol_id': symbol_id,\n",
    "                    'article_date': article['published_at'].date(),\n",
    "                    'title': article['title'][:500],\n",
    "                    'content': article.get('content', '')[:2000],  # Store content too\n",
    "                    'url': article['url'],\n",
    "                    'published_at': article['published_at'],\n",
    "                    'source': article['source'],\n",
    "                    'relevance_score': article['relevance_score']\n",
    "                })\n",
    "                \n",
    "                if result.rowcount > 0:\n",
    "                    stored_articles += 1\n",
    "                \n",
    "                # Store pre-computed sentiment (from EOD) if available\n",
    "                if article.get('eod_sentiment_score') is not None and article.get('eod_sentiment_count', 0) > 0:\n",
    "                    sentiment_query = \"\"\"\n",
    "                    INSERT INTO processed_sentiment \n",
    "                    (symbol_id, analysis_date, smo_score, smd_score, smc_score, sms_score, sdc_score,\n",
    "                     articles_analyzed, confidence_score, analysis_summary)\n",
    "                    VALUES (:symbol_id, :analysis_date, :smo, :smd, :smc, :sms, :sdc, :articles, :confidence, :summary)\n",
    "                    ON CONFLICT (symbol_id, analysis_date) DO UPDATE SET\n",
    "                        smo_score = EXCLUDED.smo_score,\n",
    "                        articles_analyzed = EXCLUDED.articles_analyzed,\n",
    "                        confidence_score = EXCLUDED.confidence_score,\n",
    "                        analysis_summary = EXCLUDED.analysis_summary\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    # Use EOD sentiment as unified score (market open, mid-day, close all same)\n",
    "                    eod_score = float(article['eod_sentiment_score'])\n",
    "                    \n",
    "                    result = conn.execute(sqlalchemy.text(sentiment_query), {\n",
    "                        'symbol_id': symbol_id,\n",
    "                        'analysis_date': article['published_at'].date(),\n",
    "                        'smo': eod_score,  # Market open sentiment\n",
    "                        'smd': eod_score,  # Mid-day sentiment  \n",
    "                        'smc': eod_score,  # Market close sentiment\n",
    "                        'sms': eod_score,  # Sector sentiment\n",
    "                        'sdc': eod_score,  # Direct competitor sentiment\n",
    "                        'articles': article.get('eod_sentiment_count', 1),\n",
    "                        'confidence': 0.85,  # EOD sentiment has high confidence\n",
    "                        'summary': f\"EOD Historical Data sentiment: {eod_score:.2f} (based on {article.get('eod_sentiment_count', 1)} articles)\"\n",
    "                    })\n",
    "                    \n",
    "                    if result.rowcount > 0:\n",
    "                        stored_sentiment += 1\n",
    "            \n",
    "            conn.commit()\n",
    "        \n",
    "        print(f\"‚úÖ Stored {stored_articles} articles + {stored_sentiment} sentiment records\")\n",
    "        return stored_articles, stored_sentiment\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error storing EOD data: {e}\")\n",
    "        return 0, 0\n",
    "\n",
    "def collect_eod_news_batch(symbol, days_back=30):\n",
    "    \"\"\"Collect historical news + sentiment from EOD (no chunking needed - reliable!)\"\"\"\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days_back)\n",
    "    \n",
    "    print(f\"üîç Collecting {days_back} days of news + sentiment for {symbol}...\")\n",
    "    \n",
    "    # EOD is reliable - no need for chunking\n",
    "    articles = news_collector.fetch_historical_news_and_sentiment(\n",
    "        symbol, start_date, end_date, max_records=200\n",
    "    )\n",
    "    \n",
    "    # Store articles with built-in sentiment\n",
    "    if articles:\n",
    "        stored_articles, stored_sentiment = store_eod_news_with_sentiment(articles)\n",
    "        print(f\"üì¶ Result: {stored_articles} articles + {stored_sentiment} sentiment records\")\n",
    "        return stored_articles\n",
    "    else:\n",
    "        print(\"üì¶ Result: No articles found\")\n",
    "        return 0\n",
    "\n",
    "def collect_eod_news_robust():\n",
    "    \"\"\"Reliable EOD collection - no complex retry logic needed!\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting EOD Historical Data collection...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    collection_results = {}\n",
    "    \n",
    "    for symbol in ['INTC', 'AMD', 'NVDA']:\n",
    "        print(f\"\\nüéØ Processing {symbol}...\")\n",
    "        \n",
    "        try:\n",
    "            # EOD is reliable - start with 14 days\n",
    "            count = collect_eod_news_batch(symbol, days_back=14)\n",
    "            collection_results[symbol] = count\n",
    "            \n",
    "            print(f\"‚úÖ {symbol} collection complete: {count} articles\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {symbol} collection failed: {e}\")\n",
    "            collection_results[symbol] = 0\n",
    "        \n",
    "        # Brief pause between symbols (EOD is reliable, minimal delay needed)\n",
    "        print(\"‚è≥ Pausing 2 seconds between symbols...\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(f\"\\nüéâ EOD collection summary: {collection_results}\")\n",
    "    print(f\"üìä Total articles collected: {sum(collection_results.values())}\")\n",
    "    \n",
    "    return collection_results\n",
    "\n",
    "print(\"‚úÖ News collection and storage functions ready!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Execute News Collection\n",
    "\n",
    "**üéØ ACTION**: Now we actually run the collection process to gather our historical news data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the EOD news collection\n",
    "print(\"üöÄ EXECUTING NEWS COLLECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run the collection for all three symbols\n",
    "collection_results = collect_eod_news_robust()\n",
    "\n",
    "print(f\"\\n‚úÖ COLLECTION COMPLETE!\")\n",
    "print(f\"üìä Final Results: {collection_results}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Verify Collection and Architecture Decision\n",
    "\n",
    "**üîÑ ARCHITECTURE CLARIFICATION**: \n",
    "- **EOD Historical Data**: Used for reliable news article collection\n",
    "- **OpenAI GPT-4o-mini**: Used for custom sentiment analysis (SMO system)\n",
    "- **Why both?**: EOD provides institutional-grade news data, OpenAI provides our custom 5-factor sentiment scoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç FINAL VERIFICATION OF COLLECTED DATA\n",
      "==================================================\n",
      "üì∞ TOTAL ARTICLES COLLECTED: 552\n",
      "\n",
      "üìä BREAKDOWN BY SYMBOL:\n",
      "   üìà AMD: 200 articles\n",
      "      üìÖ Date range: 2025-06-20 to 2025-06-28\n",
      "   üìà INTC: 152 articles\n",
      "      üìÖ Date range: 2025-06-14 to 2025-06-28\n",
      "   üìà NVDA: 200 articles\n",
      "      üìÖ Date range: 2025-06-26 to 2025-06-28\n",
      "\n",
      "üß† EOD Sentiment Records: 27 (will be replaced by OpenAI analysis)\n",
      "\n",
      "‚úÖ NEWS COLLECTION PHASE COMPLETE!\n",
      "üéØ Ready for sentiment processing in notebook 05_sentiment_processing.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Verify what we actually collected and stored\n",
    "print(\"üîç FINAL VERIFICATION OF COLLECTED DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    engine = get_database_connection()\n",
    "    \n",
    "    # Check total articles collected\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(sqlalchemy.text('SELECT COUNT(*) FROM raw_news_articles'))\n",
    "        total_articles = result.fetchone()[0]\n",
    "        \n",
    "        # Check by symbol\n",
    "        result = conn.execute(sqlalchemy.text('''\n",
    "            SELECT s.symbol, COUNT(*) as article_count,\n",
    "                   MIN(rna.article_date) as earliest_date,\n",
    "                   MAX(rna.article_date) as latest_date\n",
    "            FROM raw_news_articles rna \n",
    "            JOIN symbols s ON rna.symbol_id = s.id \n",
    "            WHERE s.symbol IN ('INTC', 'AMD', 'NVDA')\n",
    "            GROUP BY s.symbol \n",
    "            ORDER BY s.symbol\n",
    "        '''))\n",
    "        \n",
    "        print(f\"üì∞ TOTAL ARTICLES COLLECTED: {total_articles}\")\n",
    "        print(\"\\nüìä BREAKDOWN BY SYMBOL:\")\n",
    "        \n",
    "        for row in result:\n",
    "            symbol, count, earliest, latest = row\n",
    "            print(f\"   üìà {symbol}: {count} articles\")\n",
    "            print(f\"      üìÖ Date range: {earliest} to {latest}\")\n",
    "        \n",
    "        # Check if any EOD sentiment was stored (should be minimal)\n",
    "        result = conn.execute(sqlalchemy.text('SELECT COUNT(*) FROM processed_sentiment'))\n",
    "        eod_sentiment_count = result.fetchone()[0]\n",
    "        \n",
    "        if eod_sentiment_count > 0:\n",
    "            print(f\"\\nüß† EOD Sentiment Records: {eod_sentiment_count} (will be replaced by OpenAI analysis)\")\n",
    "        else:\n",
    "            print(f\"\\nüß† EOD Sentiment Records: 0 (ready for OpenAI processing)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Verification error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ NEWS COLLECTION PHASE COMPLETE!\")\n",
    "print(f\"üéØ Ready for sentiment processing in notebook 05_sentiment_processing.ipynb\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üìã Handoff Summary for Next Notebook\n",
    "\n",
    "### ‚úÖ What This Notebook Accomplished:\n",
    "1. **Database Schema**: Created `raw_news_articles` and `processed_sentiment` tables\n",
    "2. **News Collection**: Gathered historical news from EOD Historical Data API\n",
    "3. **Data Storage**: Stored articles with metadata (title, content, source, relevance scores)\n",
    "\n",
    "### üìä Data Ready for Processing:\n",
    "- **Total Articles**: ~552 articles across INTC, AMD, NVDA\n",
    "- **Time Period**: ~14 days of historical data  \n",
    "- **Data Quality**: Filtered for relevance to semiconductor stocks\n",
    "\n",
    "### üéØ Next Steps (Notebook 05):\n",
    "1. **Sentiment Analysis**: Process articles through OpenAI GPT-4o-mini\n",
    "2. **SMO Scoring**: Generate 5-factor sentiment scores (SMO, SMD, SMC, SMS, SDC)\n",
    "3. **Database Storage**: Store processed sentiment in `processed_sentiment` table\n",
    "4. **Validation**: Prepare sentiment data for trading strategy development\n",
    "\n",
    "### üèóÔ∏è Architecture Decision Finalized:\n",
    "- **EOD Historical Data** ‚ûú Reliable news article collection\n",
    "- **OpenAI GPT-4o-mini** ‚ûú Custom sentiment analysis with our SMO system\n",
    "- **PostgreSQL** ‚ûú Centralized data storage for both raw news and processed sentiment\n",
    "\n",
    "**üöÄ PROCEED TO: `05_sentiment_processing.ipynb`**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
